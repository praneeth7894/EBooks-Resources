{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.stats import pearsonr\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn import preprocessing\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "import scipy.stats as st\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'hlc_all_metrics_new_upd_final_1.csv' does not exist: b'hlc_all_metrics_new_upd_final_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5d9b62a6f6a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraw_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hlc_all_metrics_new_upd_final_1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'hlc_all_metrics_new_upd_final_1.csv' does not exist: b'hlc_all_metrics_new_upd_final_1.csv'"
     ]
    }
   ],
   "source": [
    "raw_data= pd.read_csv('hlc_all_metrics_new_upd_final_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_data['high_ltr'] = np.where(raw_data['decile_rank_last_1_yr_upd'] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_acq</th>\n",
       "      <th>fp_home</th>\n",
       "      <th>fp_ov</th>\n",
       "      <th>decile_rank</th>\n",
       "      <th>time_bn_wm_and_home</th>\n",
       "      <th>no_items_lt</th>\n",
       "      <th>auth_revenue_lt</th>\n",
       "      <th>no_divisions_lt</th>\n",
       "      <th>auth_qty_lt</th>\n",
       "      <th>no_items_lt_baby</th>\n",
       "      <th>auth_revenue_lt_baby</th>\n",
       "      <th>no_depts_lt_baby</th>\n",
       "      <th>auth_qty_lt_baby</th>\n",
       "      <th>no_items_lt_edl</th>\n",
       "      <th>auth_revenue_lt_edl</th>\n",
       "      <th>no_super_depts_lt_edl</th>\n",
       "      <th>auth_qty_lt_edl</th>\n",
       "      <th>aov_wm</th>\n",
       "      <th>ent_aov</th>\n",
       "      <th>enp_aov</th>\n",
       "      <th>edl_aov</th>\n",
       "      <th>fashion_aov</th>\n",
       "      <th>baby_care_and_safety_aov</th>\n",
       "      <th>baby_consumables_aov</th>\n",
       "      <th>baby_misc_aov</th>\n",
       "      <th>nursery_aov</th>\n",
       "      <th>avg_wm_order_gap</th>\n",
       "      <th>avg_ent_order_gap</th>\n",
       "      <th>avg_enp_order_gap</th>\n",
       "      <th>avg_edl_order_gap</th>\n",
       "      <th>avg_fashion_order_gap</th>\n",
       "      <th>avg_baby_order_gap</th>\n",
       "      <th>avg_baby_care_and_safety_order_gap</th>\n",
       "      <th>avg_baby_consumables_order_gap</th>\n",
       "      <th>avg_baby_gear_order_gap</th>\n",
       "      <th>avg_baby_misc_order_gap</th>\n",
       "      <th>avg_nursery_order_gap</th>\n",
       "      <th>accessories_and_travel_aov</th>\n",
       "      <th>automotive_parts_and_accessories_aov</th>\n",
       "      <th>baby_aov</th>\n",
       "      <th>childrens_apparel_aov</th>\n",
       "      <th>electronics_aov</th>\n",
       "      <th>fashion_misc_l1_aov</th>\n",
       "      <th>footwear_aov</th>\n",
       "      <th>grocery_and_wholesale_aov</th>\n",
       "      <th>health_beauty_and_wellness_aov</th>\n",
       "      <th>home_improvement_aov</th>\n",
       "      <th>household_and_personal_care_aov</th>\n",
       "      <th>jewelry_and_watches_aov</th>\n",
       "      <th>mens_apparel_aov</th>\n",
       "      <th>musical_instruments_arts_and_crafts_aov</th>\n",
       "      <th>outdoor_aov</th>\n",
       "      <th>pets_aov</th>\n",
       "      <th>photo_and_personalized_aov</th>\n",
       "      <th>prestige_beauty_and_personal_care_aov</th>\n",
       "      <th>sporting_goods_aov</th>\n",
       "      <th>tools_equipment_and_industrial_aov</th>\n",
       "      <th>toys_games_and_hobby_aov</th>\n",
       "      <th>video_games_books_and_other_media_aov</th>\n",
       "      <th>womens_apparel_aov</th>\n",
       "      <th>luggage_and_bags_aov</th>\n",
       "      <th>tires_and_wheels_aov</th>\n",
       "      <th>baby_gear_aov</th>\n",
       "      <th>baby_apparel_aov</th>\n",
       "      <th>tvs_audio_and_video_aov</th>\n",
       "      <th>fashion_misc_l2_aov</th>\n",
       "      <th>womens_footwear_aov</th>\n",
       "      <th>snack_food_aov</th>\n",
       "      <th>health_care_aov</th>\n",
       "      <th>home_environment_aov</th>\n",
       "      <th>paper_plastic_and_cleaning_tools_aov</th>\n",
       "      <th>jewelry_aov</th>\n",
       "      <th>mens_bottoms_aov</th>\n",
       "      <th>arts_sewing_and_crafts_aov</th>\n",
       "      <th>family_and_car_camping_aov</th>\n",
       "      <th>dog_aov</th>\n",
       "      <th>photo_web_initiated_aov</th>\n",
       "      <th>prestige_fragrances_aov</th>\n",
       "      <th>exercise_and_fitness_aov</th>\n",
       "      <th>tools_and_equipment_aov</th>\n",
       "      <th>ride_ons_aov</th>\n",
       "      <th>video_game_hardware_l2_aov</th>\n",
       "      <th>womens_intimates_aov</th>\n",
       "      <th>first_order_wm_gmv</th>\n",
       "      <th>holiday_gmv</th>\n",
       "      <th>non_holiday_gmv</th>\n",
       "      <th>avg_basket_value_delta</th>\n",
       "      <th>avg_basket_size_delta</th>\n",
       "      <th>no_home_visits</th>\n",
       "      <th>no_wm_visits</th>\n",
       "      <th>no_home_pdp_visits</th>\n",
       "      <th>home_pdp_conversion_rate</th>\n",
       "      <th>no_home_page_views</th>\n",
       "      <th>no_wm_page_views</th>\n",
       "      <th>aov_og</th>\n",
       "      <th>app_order_gmv</th>\n",
       "      <th>app_no_items</th>\n",
       "      <th>no_divisions_per_order</th>\n",
       "      <th>no_super_depts_per_order</th>\n",
       "      <th>no_depts_per_order</th>\n",
       "      <th>top_brand_revenue_percent</th>\n",
       "      <th>decile_rank_upd</th>\n",
       "      <th>last_1_yr_txn_flag</th>\n",
       "      <th>auth_revenue</th>\n",
       "      <th>decile_rank_last_1_yr</th>\n",
       "      <th>decile_rank_last_1_yr_upd</th>\n",
       "      <th>avg_dwell_time</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_group</th>\n",
       "      <th>income_group</th>\n",
       "      <th>hh_adult_qty</th>\n",
       "      <th>hh_children_qty</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>urbanicity</th>\n",
       "      <th>marital_status_cd</th>\n",
       "      <th>wm_pdp_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000134159885214</td>\n",
       "      <td>2018-04-19</td>\n",
       "      <td>2008-11-23</td>\n",
       "      <td>14</td>\n",
       "      <td>114.433333</td>\n",
       "      <td>1</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.983333</td>\n",
       "      <td>191.480</td>\n",
       "      <td>6.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.99</td>\n",
       "      <td>191.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.99</td>\n",
       "      <td>149.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389.95</td>\n",
       "      <td>-113.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>46.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>489.42</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1223.454545</td>\n",
       "      <td>F</td>\n",
       "      <td>MILLENNIALS</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Western European</td>\n",
       "      <td>SEMI URBAN</td>\n",
       "      <td>0U</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100075EAC6F1B82B</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>49</td>\n",
       "      <td>16.733333</td>\n",
       "      <td>3</td>\n",
       "      <td>39.76</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.760000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>176.39</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>1435.000000</td>\n",
       "      <td>F</td>\n",
       "      <td>MILLENNIALS</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Western European</td>\n",
       "      <td>SEMI URBAN</td>\n",
       "      <td>1M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000A54BB51EBB0F</td>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>47</td>\n",
       "      <td>45.733333</td>\n",
       "      <td>1</td>\n",
       "      <td>159.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.00</td>\n",
       "      <td>159.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>23.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>184.98</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>438.666667</td>\n",
       "      <td>F</td>\n",
       "      <td>BABY BOOMERS</td>\n",
       "      <td>LOW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>URBAN</td>\n",
       "      <td>5M</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000EA46ABBD6EE9</td>\n",
       "      <td>2018-03-23</td>\n",
       "      <td>2015-11-27</td>\n",
       "      <td>89</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>33.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.112500</td>\n",
       "      <td>23.725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.15</td>\n",
       "      <td>33.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.00</td>\n",
       "      <td>75.49</td>\n",
       "      <td>160.96</td>\n",
       "      <td>-26.956667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>35.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51.88</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>594.807692</td>\n",
       "      <td>F</td>\n",
       "      <td>BABY BOOMERS</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Western European</td>\n",
       "      <td>URBAN</td>\n",
       "      <td>1M</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010B56FC808658</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>44</td>\n",
       "      <td>19.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>41.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.910000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>197.38</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>751.500000</td>\n",
       "      <td>F</td>\n",
       "      <td>MILLENNIALS</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Western European</td>\n",
       "      <td>RURAL</td>\n",
       "      <td>0U</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          email_acq     fp_home       fp_ov  decile_rank  time_bn_wm_and_home  no_items_lt  auth_revenue_lt  no_divisions_lt  auth_qty_lt  no_items_lt_baby  auth_revenue_lt_baby  no_depts_lt_baby  auth_qty_lt_baby  no_items_lt_edl  auth_revenue_lt_edl  no_super_depts_lt_edl  auth_qty_lt_edl      aov_wm  ent_aov  enp_aov  edl_aov  fashion_aov  baby_care_and_safety_aov  baby_consumables_aov  baby_misc_aov  nursery_aov  avg_wm_order_gap  avg_ent_order_gap  avg_enp_order_gap  avg_edl_order_gap  avg_fashion_order_gap  avg_baby_order_gap  avg_baby_care_and_safety_order_gap  avg_baby_consumables_order_gap  avg_baby_gear_order_gap  avg_baby_misc_order_gap  avg_nursery_order_gap  accessories_and_travel_aov  automotive_parts_and_accessories_aov  baby_aov  childrens_apparel_aov  electronics_aov  fashion_misc_l1_aov  footwear_aov  grocery_and_wholesale_aov  health_beauty_and_wellness_aov  home_improvement_aov  household_and_personal_care_aov  jewelry_and_watches_aov  mens_apparel_aov  \\\n",
       "0  1000134159885214  2018-04-19  2008-11-23           14           114.433333            1             6.99                1            1               NaN                   NaN               NaN               NaN              NaN                  NaN                    NaN              NaN  129.983333  191.480     6.99      NaN          NaN                       NaN                   NaN            NaN          NaN               4.0                6.0               12.0                NaN                    NaN                 NaN                                 NaN                             NaN                      NaN                      NaN                    NaN                         NaN                                   NaN       NaN                    NaN              NaN                  NaN           NaN                        NaN                             NaN                   NaN                              NaN                      NaN               NaN   \n",
       "1  100075EAC6F1B82B  2018-04-01  2016-11-14           49            16.733333            3            39.76                1            3               NaN                   NaN               NaN               NaN              NaN                  NaN                    NaN              NaN   39.760000      NaN      NaN      NaN        39.76                       NaN                   NaN            NaN          NaN              12.0                NaN                NaN                NaN                   12.0                 NaN                                 NaN                             NaN                      NaN                      NaN                    NaN                         NaN                                   NaN       NaN                  39.76              NaN                  NaN           NaN                        NaN                             NaN                   NaN                              NaN                      NaN               NaN   \n",
       "2  1000A54BB51EBB0F  2018-03-02  2014-05-30           47            45.733333            1           159.00                1            1               NaN                   NaN               NaN               NaN              NaN                  NaN                    NaN              NaN  159.000000  159.000      NaN      NaN          NaN                       NaN                   NaN            NaN          NaN              12.0               12.0                NaN                NaN                    NaN                 NaN                                 NaN                             NaN                      NaN                      NaN                    NaN                         NaN                                   NaN       NaN                    NaN            159.0                  NaN           NaN                        NaN                             NaN                   NaN                              NaN                      NaN               NaN   \n",
       "3  1000EA46ABBD6EE9  2018-03-23  2015-11-27           89            28.200000            1            33.99                1            1               NaN                   NaN               NaN               NaN              4.0                40.15                    1.0              4.0   59.112500   23.725      NaN    40.15        33.99                       NaN                   NaN            NaN          NaN               3.0                6.0                NaN               12.0                   12.0                 NaN                                 NaN                             NaN                      NaN                      NaN                    NaN                       33.99                                   NaN       NaN                    NaN              NaN                  NaN           NaN                        NaN                           40.15                   NaN                              NaN                      NaN               NaN   \n",
       "4  10010B56FC808658  2018-04-06  2016-09-06           44            19.233333            1            41.91                1            1               NaN                   NaN               NaN               NaN              1.0                41.91                    1.0              1.0   41.910000      NaN      NaN    41.91          NaN                       NaN                   NaN            NaN          NaN              12.0                NaN                NaN               12.0                    NaN                 NaN                                 NaN                             NaN                      NaN                      NaN                    NaN                         NaN                                   NaN       NaN                    NaN              NaN                  NaN           NaN                        NaN                           41.91                   NaN                              NaN                      NaN               NaN   \n",
       "\n",
       "   musical_instruments_arts_and_crafts_aov  outdoor_aov  pets_aov  photo_and_personalized_aov  prestige_beauty_and_personal_care_aov  sporting_goods_aov  tools_equipment_and_industrial_aov  toys_games_and_hobby_aov  video_games_books_and_other_media_aov  womens_apparel_aov  luggage_and_bags_aov  tires_and_wheels_aov  baby_gear_aov  baby_apparel_aov  tvs_audio_and_video_aov  fashion_misc_l2_aov  womens_footwear_aov  snack_food_aov  health_care_aov  home_environment_aov  paper_plastic_and_cleaning_tools_aov  jewelry_aov  mens_bottoms_aov  arts_sewing_and_crafts_aov  family_and_car_camping_aov  dog_aov  photo_web_initiated_aov  prestige_fragrances_aov  exercise_and_fitness_aov  tools_and_equipment_aov  ride_ons_aov  video_game_hardware_l2_aov  womens_intimates_aov  first_order_wm_gmv  holiday_gmv  non_holiday_gmv  avg_basket_value_delta  avg_basket_size_delta  no_home_visits  no_wm_visits  no_home_pdp_visits  home_pdp_conversion_rate  no_home_page_views  no_wm_page_views  aov_og  \\\n",
       "0                                      NaN          NaN       NaN                         NaN                                    NaN                 NaN                                6.99                    191.48                                    NaN                 NaN                   NaN                   NaN            NaN               NaN                      NaN                  NaN                  NaN             NaN              NaN                   NaN                                   NaN          NaN               NaN                         NaN                         NaN      NaN                      NaN                      NaN                       NaN                     6.99        149.97                         NaN                   NaN               39.97          NaN           389.95             -113.000000                    0.0             3.0          11.0                 2.0                      0.00            2.000000         46.090909     NaN   \n",
       "1                                      NaN          NaN       NaN                         NaN                                    NaN                 NaN                                 NaN                       NaN                                    NaN                 NaN                   NaN                   NaN            NaN             39.76                      NaN                  NaN                  NaN             NaN              NaN                   NaN                                   NaN          NaN               NaN                         NaN                         NaN      NaN                      NaN                      NaN                       NaN                      NaN           NaN                         NaN                   NaN               51.89          NaN            39.76                     NaN                    NaN             1.0           1.0                 1.0                      1.00           20.000000         53.000000     NaN   \n",
       "2                                      NaN          NaN       NaN                         NaN                                    NaN                 NaN                                 NaN                       NaN                                    NaN                 NaN                   NaN                   NaN            NaN               NaN                      NaN                  NaN                  NaN             NaN              NaN                   NaN                                   NaN          NaN               NaN                         NaN                         NaN      NaN                      NaN                      NaN                       NaN                      NaN           NaN                         NaN                   NaN              179.00       159.00              NaN                     NaN                    NaN             4.0           6.0                 4.0                      0.25            6.666667         23.833333     NaN   \n",
       "3                                     5.95          NaN       NaN                         NaN                                    NaN                 NaN                                 NaN                     41.50                                    NaN                 NaN                   NaN                   NaN            NaN               NaN                      NaN                  NaN                  NaN             NaN              NaN                   NaN                                   NaN          NaN               NaN                         NaN                         NaN      NaN                      NaN                      NaN                       NaN                      NaN           NaN                         NaN                   NaN               88.00        75.49           160.96              -26.956667                    0.0             3.0          26.0                 2.0                      0.00            0.230769         35.153846     NaN   \n",
       "4                                      NaN          NaN       NaN                         NaN                                    NaN                 NaN                                 NaN                       NaN                                    NaN                 NaN                   NaN                   NaN            NaN               NaN                      NaN                  NaN                  NaN             NaN            41.91                   NaN                                   NaN          NaN               NaN                         NaN                         NaN      NaN                      NaN                      NaN                       NaN                      NaN           NaN                         NaN                   NaN               28.41          NaN            41.91                     NaN                    NaN             1.0           2.0                 1.0                      1.00            7.000000         21.000000     NaN   \n",
       "\n",
       "   app_order_gmv  app_no_items  no_divisions_per_order  no_super_depts_per_order  no_depts_per_order  top_brand_revenue_percent  decile_rank_upd  last_1_yr_txn_flag  auth_revenue  decile_rank_last_1_yr  decile_rank_last_1_yr_upd  avg_dwell_time gender     age_group income_group  hh_adult_qty  hh_children_qty         ethnicity  urbanicity marital_status_cd  wm_pdp_visits  \n",
       "0            NaN           NaN                0.666667                  0.666667                1.00                        NaN                1                   1        489.42                     14                          1     1223.454545      F   MILLENNIALS       MEDIUM           4.0              1.0  Western European  SEMI URBAN                0U            5.0  \n",
       "1            NaN           NaN                1.000000                  1.000000                1.00                        NaN                2                   1        176.39                     49                          2     1435.000000      F   MILLENNIALS         HIGH           2.0              2.0  Western European  SEMI URBAN                1M            1.0  \n",
       "2            NaN           NaN                1.000000                  1.000000                1.00                        1.0                2                   1        184.98                     47                          2      438.666667      F  BABY BOOMERS          LOW           1.0              0.0          Hispanic       URBAN                5M            4.0  \n",
       "3            NaN           NaN                1.000000                  1.250000                1.25                        NaN                3                   1         51.88                     88                          3      594.807692      F  BABY BOOMERS       MEDIUM           3.0              0.0  Western European       URBAN                1M            6.0  \n",
       "4            NaN           NaN                1.000000                  1.000000                1.00                        NaN                2                   1        197.38                     44                          2      751.500000      F   MILLENNIALS         HIGH           2.0              1.0  Western European       RURAL                0U            2.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix = raw_data.corr(method='pearson',min_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix.to_excel('Correlation_matrix.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_data.count()\n",
    "raw_data.isnull().sum().to_excel('Number_of_nulls.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_sel_cols = raw_data[['email_acq','time_bn_wm_and_home','no_items_lt','auth_revenue_lt','no_items_lt_edl','aov_wm','ent_aov','enp_aov','fashion_aov',\n",
    "             'avg_wm_order_gap','first_order_wm_gmv','holiday_gmv','non_holiday_gmv','avg_basket_value_delta','no_home_visits',\n",
    "             'no_home_page_views','no_divisions_per_order','top_brand_revenue_percent','avg_dwell_time', 'gender', 'age_group', 'income_group', \n",
    "                       'hh_adult_qty', 'hh_children_qty', 'ethnicity', 'urbanicity', 'marital_status_cd', 'wm_pdp_visits', 'decile_rank_last_1_yr', 'auth_revenue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email_acq                         0\n",
       "time_bn_wm_and_home               0\n",
       "no_items_lt                       0\n",
       "auth_revenue_lt                   0\n",
       "no_items_lt_edl              213588\n",
       "aov_wm                            0\n",
       "ent_aov                      138932\n",
       "enp_aov                      255696\n",
       "fashion_aov                  265214\n",
       "avg_wm_order_gap                  0\n",
       "first_order_wm_gmv                0\n",
       "holiday_gmv                  197603\n",
       "non_holiday_gmv               61033\n",
       "avg_basket_value_delta       235570\n",
       "no_home_visits                27094\n",
       "no_home_page_views            27094\n",
       "no_divisions_per_order            0\n",
       "top_brand_revenue_percent    273102\n",
       "avg_dwell_time                27094\n",
       "gender                        77880\n",
       "age_group                     77874\n",
       "income_group                  77874\n",
       "hh_adult_qty                  78309\n",
       "hh_children_qty               77928\n",
       "ethnicity                     77874\n",
       "urbanicity                    78032\n",
       "marital_status_cd             78029\n",
       "wm_pdp_visits                 27094\n",
       "decile_rank_last_1_yr             0\n",
       "auth_revenue                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_sel_cols.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_sel_cols1 = data_with_sel_cols.fillna('NULL')\n",
    "data_with_sel_cols1.to_excel('Raw_data_with_selected_columns1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_imputed = pd.read_csv('Raw_data_with_selected_columns1_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing one hot encoder from sklearn \n",
    "#import sklearn\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(final_data.drop(['high_ltr'], axis= 1), final_data['high_ltr'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(final_data1.drop(['high_ltr'], axis= 1), final_data1['high_ltr'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic= LogisticRegression()\n",
    "logistic.fit(x_train, y_train)\n",
    "logistic_prediction= logistic.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic= LogisticRegression()\n",
    "logistic.fit(x_train1, y_train1)\n",
    "logistic_prediction= logistic.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.94      0.78     75803\n",
      "          1       0.34      0.06      0.10     37493\n",
      "\n",
      "avg / total       0.56      0.65      0.56    113296\n",
      "\n",
      "Accuracy: 0.6503936590876995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[71469,  4334],\n",
       "       [35275,  2218]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "print(classification_report(y_test,logistic_prediction))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, logistic_prediction))\n",
    "metrics.confusion_matrix(y_test, logistic_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.97      0.80     75935\n",
      "          1       0.60      0.11      0.18     37361\n",
      "\n",
      "avg / total       0.66      0.68      0.60    113296\n",
      "\n",
      "Accuracy: 0.6817981217342183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[73314,  2621],\n",
       "       [33430,  3931]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "print(classification_report(y_test1,logistic_prediction))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test1, logistic_prediction))\n",
    "metrics.confusion_matrix(y_test1, logistic_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K- NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(x_train, y_train)\n",
    "knn_prediction= knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(x_train1, y_train1)\n",
    "knn_prediction= knn.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.81      0.74     75803\n",
      "          1       0.38      0.23      0.29     37493\n",
      "\n",
      "avg / total       0.58      0.62      0.59    113296\n",
      "\n",
      "Accuracy: 0.6223167631690439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[61762, 14041],\n",
       "       [28749,  8744]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test,knn_prediction))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, knn_prediction))\n",
    "metrics.confusion_matrix(y_test, knn_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.81      0.74     75935\n",
      "          1       0.39      0.24      0.29     37361\n",
      "\n",
      "avg / total       0.59      0.62      0.60    113296\n",
      "\n",
      "Accuracy: 0.6239584804406157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[61845, 14090],\n",
       "       [28514,  8847]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test1,knn_prediction))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test1, knn_prediction))\n",
    "metrics.confusion_matrix(y_test1, knn_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb= BernoulliNB()\n",
    "nb.fit(x_train, y_train)\n",
    "nb_prediction= nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb= BernoulliNB()\n",
    "nb.fit(x_train1, y_train1)\n",
    "nb_prediction= nb.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80     75803\n",
      "          1       0.00      0.00      0.00     37493\n",
      "\n",
      "avg / total       0.45      0.67      0.54    113296\n",
      "\n",
      "Accuracy: 0.6690703996610649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[75803,     0],\n",
       "       [37493,     0]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test,nb_prediction))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, nb_prediction))\n",
    "metrics.confusion_matrix(y_test, nb_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      1.00      0.80     75935\n",
      "          1       0.00      0.00      0.00     37361\n",
      "\n",
      "avg / total       0.45      0.67      0.54    113296\n",
      "\n",
      "Accuracy: 0.6702354893376642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[75935,     0],\n",
       "       [37361,     0]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test1,nb_prediction))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test1, nb_prediction))\n",
    "metrics.confusion_matrix(y_test1, nb_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71469,  4334],\n",
       "       [35275,  2218]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, logistic_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73314,  2621],\n",
       "       [33430,  3931]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test1, logistic_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60501, 15302],\n",
       "       [29858,  7635]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, knn_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61845, 14090],\n",
       "       [28514,  8847]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test1, knn_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75803,     0],\n",
       "       [37493,     0]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, nb_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75935,     0],\n",
       "       [37361,     0]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test1, nb_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression fetches the best results with an accuracy of 95.1%. This is because, Logitic regression works well with Yes/No scenarios. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
